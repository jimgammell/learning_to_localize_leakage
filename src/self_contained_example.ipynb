{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e55ab10",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Python libraries\n",
    "import os\n",
    "from math import log, log1p\n",
    "from typing import Callable\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party Python libraries\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Our own libraries\n",
    "from common import *\n",
    "from datasets.ascadv1 import ASCADv1, ascadv1_download # A second-order leaking dataset we'll use for this example\n",
    "from utils.metrics import get_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASCADv1_ROOT = os.path.join(RESOURCE_DIR, 'ascadv1-fixed') # Dataset will be auto-downloaded here if not already present. Feel free to change this directory.\n",
    "\n",
    "training_steps = 10000\n",
    "minibatch_size = 256\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "gamma_budget = 0.5 # Budget hyperparameter, equal to the value of \\gamma when \\eta is uniform. Called \\overline{\\gamma} in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74476ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ascadv1_download(ASCADv1_ROOT) # make sure the dataset has been downloaded and extracted\n",
    "profiling_dataset = ASCADv1(root=ASCADv1_ROOT, train=True, variable_keys=False) # train dataset (called 'profiling' dataset by side-channel community)\n",
    "attack_dataset = ASCADv1(root=ASCADv1_ROOT, train=False, variable_keys=False) # test dataset (called 'attack' dataset by side-channel community)\n",
    "input_features = profiling_dataset.timesteps_per_trace # called T in the paper\n",
    "output_classes = profiling_dataset.class_count # cardinality of \\mathsf{Y} in the paper\n",
    "train_dataset, val_dataset = random_split(profiling_dataset, lengths=(40000, 10000))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2*minibatch_size)\n",
    "attack_dataloader = DataLoader(attack_dataset, batch_size=2*minibatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d47791",
   "metadata": {},
   "source": [
    "## Computing the oracle signal to noise ratio\n",
    "\n",
    "The basic approach when carrying out a side-channel attack on AES-128 is to target an internal variable called the first SubBytes output. This variable is defined as $S := \\operatorname{Sbox}(k \\oplus w)$ where $k$ denotes one byte of the cryptographic key, $w$ denotes the corresponding byte of the plaintext, $\\oplus$ denotes the bitwise exclusive-or operation, and $\\operatorname{Sbox}$ denotes an invertible nonlinear operation which is the same for all AES implementations. Note that the plaintext is not a secret, so if the attacker can determine $S$, they can then compute the corresponding byte of the key as $k = \\operatorname{Sbox}^{-1}(S) \\oplus w.$\n",
    "\n",
    "Since the SubBytes is a major target of attackers, the designers of AES algorithms have developed countermeasures to make it more difficult to attack. In the implementations from which the ASCADv1 datasets were collected, the SubBytes variable is protected by a countermeasure called Boolean masking. Before every encryption, random bytes called *masks* are sampled uniformly at random. Note that for random bit $b$ with arbitrary distribution, if we generate a random mask bit as $r \\sim \\mathcal{U}\\{0, 1\\}$, the variable $b \\oplus r$ is now statistically independent of $b$. The same is true if $b$ and $r$ are bitstrings (e.g. bytes) rather than single bits. Boolean masking exploits this fact by modifying the AES algorithm so that the SubBytes variable $S$ is never directly operated on and therefore never directly influences power consumption or EM radiation. The algorithm operates only on variables $S \\oplus r$ for various mask variables $r$. Thus, attackers must determine ordered pairs $(r, S \\oplus r)$ to determine $S$, where $r$ and $S \\oplus r$ are usually leaked at temporally-distant points in time. While deep learning methods have proven capable of overcoming countermeasures of this nature, they make it significantly harder to attack using older parametric statistics-based techniques. Refer to algorithm 1 of Benadjila et al. (2020) for details.\n",
    "\n",
    "Boolean-masked implementations often leak due to many such pairs of internal AES variables. Identification of these variables generally requires significant domain knowledge and careful analysis of the AES implementation, as well as knowledge of the internally-generated random mask variables of the implementation (on top of the key and plaintext, which are commonly assumed to be known to attackers during the 'profiling' phase of their attack). In Benadjila et al. (2020), the creators of the ASCADv1 datasets identified 2 pairs of random variables which leak. 2 additional pairs were subsequently discovered by Egger et al. (2022). In the side-channel community, leakage localization for non-masked datasets is usually done using simple first-order parametric statistical methods such as computing the signal to noise ratio between individual power measurements and the SubBytes variable. This does not work for second-order datasets such as ASCADv1 because each individual power measurement is by design nearly-independent of the SubBytes variable. However, it is possible to individually target each of the leaky internal AES variables with such techniques, then average the 'leakiness' assessments to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3984c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    # This is the standard target when carrying out AES attacks. While this variable *does* leak from the ASCADv1 datasets,\n",
    "    #  because they are Boolean masked we cannot identify the leaking points with the standard first-order parametric statistical techniques.\n",
    "    'subbytes',\n",
    "\n",
    "    # These are the pairs of leaking variables identified by Egger et al. (2022). It is possible to use the standard first-order methods to\n",
    "    #  identify leaking points for these individual variables, then average the results to get a list of leaky points for SubBytes.\n",
    "    'r_in', 'plaintext__key__r_in',\n",
    "    'r', 'subbytes__r',\n",
    "    'r_out', 'subbytes__r_out',\n",
    "    's_prev__subbytes__r_out', 'security_load'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = nn.Sequential( # called \\Phi_\\theta in the paper\n",
    "    nn.Linear(2*input_features, 500), # factor of 2 because we are feeding it both the power trace and the occlusion mask\n",
    "    nn.ReLU(),\n",
    "    *sum([[nn.Linear(500, 500), nn.ReLU()] for _ in range(3)], start=[]),\n",
    "    nn.Linear(500, output_classes)\n",
    ")\n",
    "eta_tau = 0.01*torch.randn(input_features) # the erasure probability logits before reparameterizing for the budget constraint, called \\tilde{\\bm{\\eta}} in the paper\n",
    "eta_tau.requires_grad_(True)\n",
    "theta_optimizer = optim.Adam(classifiers.parameters(), lr=1e-4)\n",
    "etat_optimizer = optim.Adam([eta_tau], lr=1e-3)\n",
    "print(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1779915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_erasure_prob_logits(eta_tau: torch.Tensor, gamma_budget: float) -> torch.Tensor: # equation 6 in paper\n",
    "    gamma_tau = eta_tau - torch.logsumexp(eta_tau.squeeze(0), dim=0) + log(input_features) + log(gamma_budget) - log1p(-gamma_budget)\n",
    "    return gamma_tau\n",
    "\n",
    "def sample_from_concrete_distribution(batch_size: int, prob_logits: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:\n",
    "    # for numerical stability it's important to keep these log-scale instead of e.g. passing probabilities and taking log\n",
    "    log_probs = nn.functional.logsigmoid(prob_logits).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    log_1mprobs = nn.functional.logsigmoid(-prob_logits).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    u = torch.rand_like(log_probs).clamp_(min=1e-6, max=1-1e-6) # clamping to avoid taking log of 0\n",
    "    concrete_sample = nn.functional.sigmoid((log_probs - log_1mprobs + u.log() - (1-u).log())/temperature)\n",
    "    return concrete_sample\n",
    "\n",
    "def get_masked_logits(classifiers: Callable[[torch.Tensor, torch.Tensor], torch.Tensor], x: torch.Tensor, mask: torch.Tensor):\n",
    "    masked_input = (1-mask)*x + mask*torch.randn_like(x)\n",
    "    logits = classifiers(torch.cat([masked_input, 1-mask], dim=-1))\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_curves = defaultdict(list)\n",
    "step_idx = 0\n",
    "progress_bar = tqdm(total=training_steps)\n",
    "while step_idx < training_steps:\n",
    "    for x, y in train_dataloader:\n",
    "        batch_size, *_ = x.shape\n",
    "        gamma_tau = get_erasure_prob_logits(eta_tau, gamma_budget)\n",
    "        mask = sample_from_concrete_distribution(batch_size, gamma_tau)\n",
    "        classifier_logits = get_masked_logits(classifiers, x, mask)\n",
    "        theta_loss = nn.functional.cross_entropy(classifier_logits, y)\n",
    "        eta_tau_loss = -theta_loss\n",
    "        theta_optimizer.zero_grad()\n",
    "        etat_optimizer.zero_grad()\n",
    "        theta_loss.backward(retain_graph=True, inputs=list(classifiers.parameters()))\n",
    "        eta_tau_loss.backward(inputs=list(eta_tau))\n",
    "        theta_optimizer.step()\n",
    "        etat_optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            training_curves['train_loss'].append(theta_loss.item())\n",
    "            training_curves['classifiers_rank'].append(get_rank(classifier_logits, y).mean().item()) # Lower === more-accurate.\n",
    "        step_idx += 1\n",
    "        progress_bar.update(1)\n",
    "        if step_idx >= training_steps:\n",
    "            break\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_rank = [], []\n",
    "        for x, y in val_dataloader():\n",
    "            batch_size, *_ = x.shape\n",
    "            gamma_tau = get_erasure_prob_logits(eta_tau, gamma_budget)\n",
    "            mask = sample_from_concrete_distribution(batch_size, gamma_tau)\n",
    "            logits = get_masked_logits(classifiers, x, mask)\n",
    "            loss = nn.functional.cross_entropy(classifier_logits, y)\n",
    "            val_loss.append(loss.item())\n",
    "            val_rank.append(get_rank(logits, y).mean().item())\n",
    "        training_curves['val_loss'].append(np.mean(val_loss))\n",
    "        training_curves['val_rank'].append(np.mean(val_rank))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
